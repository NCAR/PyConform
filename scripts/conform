#!/usr/bin/env python
"""
PyConform - Command-Line Interface

This is the command-line interface to the PyConform tool.  It takes input from
the command-line directly, and from an "output specification" file, which
defines the output dataset entirely.

COPYRIGHT: 2016, University Corporation for Atmospheric Research
LICENSE: See the LICENSE.rst file for details
"""

from os.path import exists
from glob import glob
from json import load as json_load
from collections import OrderedDict
from argparse import ArgumentParser

from pyconform.datasets import InputDataset, OutputDataset
from pyconform.dataflow import DataFlow


#===================================================================================================
# chunk
#===================================================================================================
def chunk(arg):
    try:
        name, size_str = arg.split(',')
        size = int(size_str)
        return name, size
    except:
        raise argparse.ArgumentTypeError("Chunks must be formatted as 'name,size'")


#==============================================================================
# Command-line Interface
#==============================================================================
def cli(argv=None):
    desc = """This is the PyConform command-line tool.  This scripts takes
              input from the command-line and a predefined output
              specification file (specfile)."""

    parser = ArgumentParser(description=desc)
    parser.add_argument('-c', '--chunk', dest='chunks', default=[],
                        metavar='NAME,SIZE', action='append', type=chunk,
                        help='Chunk sizes for each dimension specified in the '
                             'output specification file.  Data will be read/written '
                             'in sizes given by these chunks. [No chunking]')
    parser.add_argument('-i', '--infile', dest='infiles', default=[],
                        metavar='INFILE', action='append', type=str,
                        help='Input file path or globstring specifying input '
                             'data for the PyConform operation.  If no input '
                             'files are specified, then PyConform will validate '
                             'the output specification file only, and then '
                             'exit.  [No default]')
    parser.add_argument('-e', '--error', default=False,
                        action='store_true', dest='error',
                        help='Whether to error when validation checks do not pass '
                             ' (True) or simply print a warning message (False)'
                             '[Default: False]')
    parser.add_argument('-n', '--nocycle', default=False,
                        action='store_true', dest='nocycle',
                        help='Whether to cycle over input files for metadata (False)'
                             ' or read all metadata from the first input file (True)'
                             '[Default: False]')
    parser.add_argument('-s', '--serial', default=False,
                        action='store_true', dest='serial',
                        help='Whether to run in serial (True) or parallel '
                             '(False). [Default: False]')
    parser.add_argument('specfile', default=None, metavar='SPECFILE', type=str,
                        help='JSON-formatted output specification file '
                             '[REQUIRED]')

    return parser.parse_args(argv)


#==============================================================================
# Main Script Function
#==============================================================================
def main(argv=None):
    args = cli(argv)

    infiles = []
    for infile in args.infiles:
        infiles.extend(glob(infile))

    if not exists(args.specfile):
        raise OSError(('Output specification file {!r} not '
                       'found').format(args.specfile))
    dsdict = json_load(open(args.specfile, 'r'), object_pairs_hook=OrderedDict)

    # Parse the input/output Datasets
    inpds = InputDataset(filenames=infiles)
    outds = OutputDataset(dsdict=dsdict)

    # Setup the PyConform data flow
    dataflow = DataFlow(inpds, outds, cycle=(not args.nocycle), error=args.error)

    # Execute the data flow (write to files)
    dataflow.execute(chunks=dict(args.chunks), serial=args.serial)


#==============================================================================
# Command-line Operation
#==============================================================================
if __name__ == '__main__':
    main()
