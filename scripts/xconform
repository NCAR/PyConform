#!/usr/bin/env python
"""
PyConform - Command-Line Interface

This command-line tool is designed to run PyConform, given a "standardization file" (a
JSON-formatted file specifying the output variables, files and formats, and how to construct
the output variables from input variables) and a collection of "input NetCDF files" containing
the data to be standardized.

COPYRIGHT: 2017, University Corporation for Atmospheric Research
LICENSE: See the LICENSE.rst file for details
"""

from os.path import exists
from glob import glob
from json import load as json_load
from collections import OrderedDict
from argparse import ArgumentParser, ArgumentTypeError
from warnings import simplefilter
from datetime import datetime

from pyconform.datasets import InputDatasetDesc, OutputDatasetDesc
from pyconform.dataflow import DataFlow
from pyconform.flownodes import ValidationWarning


#===================================================================================================
# chunk - Chunksize for a named dimension
#===================================================================================================
def chunk(arg):
    try:
        name, size_str = arg.split(',')
        size = int(size_str)
        return name, size
    except:
        raise ArgumentTypeError("Chunks must be formatted as 'name,size'")


#===================================================================================================
# Command-line Interface
#===================================================================================================
def cli(argv=None):
    desc = """This is the PyConform command-line tool.  This scripts takes
              input from the command-line and a predefined output
              specification file (specfile)."""

    parser = ArgumentParser(description=desc)
    parser.add_argument('-c', '--chunk', dest='chunks', default=[],
                        metavar='NAME,SIZE', action='append', type=chunk,
                        help=('Chunk sizes for each dimension specified in the '
                              'output specification file.  Data will be read/written '
                              'in sizes given by these chunks. [Default: no chunking]'))
    parser.add_argument('-f', '--stdfile', default=None, metavar='STANDARDIZATION', type=str,
                        help=('JSON-formatted standardization (output specification) file '
                              '[REQUIRED]'))
    parser.add_argument('-e', '--error', default=False, action='store_true',
                        help=('Whether to error when validation checks do not pass (True) or '
                              'simply print a warning message (False) [Default: False]'))
    parser.add_argument('-n', '--no_history', default=False, action='store_true',
                        help=('Whether to omit the addition of the "history" attribute in each '
                              'output variable, which stores the provenance information generated '
                              'at execution time [Default: False]'))
    parser.add_argument('-s', '--serial', default=False, action='store_true',
                        help=('Whether to run in serial (True) or parallel '
                              '(False). [Default: False]'))
    parser.add_argument('infiles', metavar='INFILE', nargs='*', type=str,
                        help=('Input file path or globstring specifying input data for the '
                              'PyConform operation.  If no input files are specified, then '
                              'PyConform will validate the output specification file only, and '
                              'then exit.  [No default]'))

    return parser.parse_args(argv)


#===================================================================================================
# Main Script Function
#===================================================================================================
def main(argv=None):
    args = cli(argv)
    
    # Gather the list of input files
    infiles = []
    for infile in args.infiles:
        infiles.extend(glob(infile))

    # Check that the specfile exists
    if not exists(args.specfile):
        raise OSError(('Output specification file {!r} not '
                       'found').format(args.specfile))
    
    # Read the specfile into a dictionary
    dsdict = json_load(open(args.specfile, 'r'), object_pairs_hook=OrderedDict)

    # Parse the output Dataset
    outds = OutputDatasetDesc(dsdict=dsdict)

    # If no input files, stop here
    if len(infiles) == 0:
        return

    # Parse the input Dataset
    inpds = InputDatasetDesc(filenames=infiles)

    # Check for warn/error
    if args.error:
        simplefilter("error", ValidationWarning)

    # Setup the PyConform data flow
    dataflow = DataFlow(inpds, outds)

    # Execute the data flow (write to files)
    dataflow.execute(chunks=dict(args.chunks), serial=args.serial,
                     provenance=args.provenance, bounds=bounds)


#===================================================================================================
# Command-line Operation
#===================================================================================================
if __name__ == '__main__':
    main()
